{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy the model as an online endpoint\n",
        "\n",
        "This Notebook deploy a ML trained by Notebook 01 as an realtime online endpoint. This enables applications to send a json request with data to get a prediction.\n",
        "\n",
        "**Note**: This notebook is intended to be run by a Compute Instance in Azure Machine Learning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "# authenticate\n",
        "credential = DefaultAzureCredential()\n",
        "\n",
        "SUBSCRIPTION = \"<subscription-id>\"\n",
        "RESOURCE_GROUP = \"rg-we-atpws-aml\"\n",
        "WS_NAME = \"aml-ws-atp001\"\n",
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1763628658307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "registered_model_name = \"credit_default_prediction_standard\" #Trained by Notebook 01"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1763165714762
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a new online endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Creating a unique name for the endpoint\n",
        "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1763165714931
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        ")\n",
        "\n",
        "# create an online endpoint\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=online_endpoint_name,\n",
        "    description=\"this is an online endpoint\",\n",
        "    auth_mode=\"key\",\n",
        "    tags={\n",
        "        \"training_dataset\": \"credit_defaults\",\n",
        "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
        "\n",
        "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint credit-endpoint-78a2c255 provisioning state: Succeeded\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1763165810429
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
        "\n",
        "print(\n",
        "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Endpoint \"credit-endpoint-78a2c255\" with provisioning state \"Succeeded\" is retrieved\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1763165810599
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model to the endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick the latest version of the model\n",
        "latest_model_version = max(\n",
        "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1763470593991
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# picking the model to deploy. Here we use the latest version of our registered model\n",
        "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
        "\n",
        "\n",
        "# create an online deployment.\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    model=model,\n",
        "    instance_type=\"Standard_DS3_v2\",\n",
        "    instance_count=1,\n",
        ")\n",
        "\n",
        "blue_deployment = ml_client.begin_create_or_update(blue_deployment).result()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Check: endpoint credit-endpoint-78a2c255 exists\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "..............................................................................."
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1763166243610
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with a sample query"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deploy_dir = \"./deploy\"\n",
        "os.makedirs(deploy_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1763628660108
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Simulate a json payload that is to be send to the ML endpoint**"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile {deploy_dir}/sample-request.json\n",
        "{\n",
        "  \"input_data\": {\n",
        "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25],\n",
        "    \"index\": [0, 1],\n",
        "    \"data\": [\n",
        "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0,0,0,0],\n",
        "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8,0,0,0]\n",
        "        ]\n",
        "  }\n",
        "}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting ./deploy/sample-request.json\n"
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test against ML endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test the blue deployment with some sample data\n",
        "ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1763166730607
        },
        "editable": false,
        "run_control": {
          "frozen": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Realtime specfic Endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Excute step1 and -3, -2 of this cell\n",
        "\n",
        "#hardcoding to endpoint\n",
        "result = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=\"credit-endpoint-78a2c255\", #Hard-coded enpoint\n",
        "    request_file=\"./deploy/sample-request.json\",\n",
        "    deployment_name=\"blue\",\n",
        ")\n",
        "\n",
        "print(result)  # This will show the raw response\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[1, 0]\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1763628674586
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up resources - Delete endpoint"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "editable": false,
        "run_control": {
          "frozen": true
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}