{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Saving Model Card in Onelake\n",
        "Note: Run this notebook in Azure Machine Learning Severless Spark Compute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Saving model card as csv in OneLake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install azure-ai-ml azure-identity pyspark delta-spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Save Model Card as delta table in Onelake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1763474313877
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2025-11-18T13:58:33.3249014Z",
              "execution_start_time": "2025-11-18T13:57:01.7041268Z",
              "livy_statement_state": "available",
              "normalized_state": "finished",
              "parent_msg_id": "75a98a68-2733-4765-a824-749eae31e49a",
              "queued_time": "2025-11-18T13:49:50.2056013Z",
              "session_id": "6",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [
                  {
                    "completionTime": "2025-11-18T13:58:31.317GMT",
                    "dataRead": 2027,
                    "dataWritten": 0,
                    "description": "Job group for statement 16:\n#Execute through Serveress Spark Compute\n\n# Install required packages:\n# %pip install azure-ai-ml azure-identity pyspark delta-spark\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import ClientSecretCredential\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, MapType\nfrom delta import configure_spark_with_delta_pip\n\n# ---------------------------\n# 2. Service Principal Credentials\n# ---------------------------\ntenant_id = \"c560c3d4-de3a-4441-b221-48582ef51cc4\"\nclient_id = \"cc69fe2b-46cd-4a05-89fa-d83f8fc037d6\"\nclient_secret = \"mny8Q~YARqDd7_m~Hujd6xXPNvi-aiplYxuAqdt0\"\n\ncredential = ClientSecretCredential(tenant_id, client_id, client_secret)\n\n# ---------------------------\n# 3. AML Workspace Details\n# ---------------------------\nSUBSCRIPTION = \"<subscription-id>\"\nRESOURCE_GROUP = \"rg-we-atpws-aml\"\nWS_NAME = \"aml-ws-atp001\"\n\nml_client = MLClient(\n    credential=credential,\n    subscription_id=SUBSCRIPTION,\n    resource_group_name=RESO...",
                    "displayName": "toString at String.java:2951",
                    "jobGroup": "16",
                    "jobId": 2,
                    "jobTags": [],
                    "killedTasksSummary": {},
                    "name": "toString at String.java:2951",
                    "numActiveStages": 0,
                    "numActiveTasks": 0,
                    "numCompletedIndices": 1,
                    "numCompletedStages": 1,
                    "numCompletedTasks": 1,
                    "numFailedStages": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numSkippedStages": 0,
                    "numSkippedTasks": 0,
                    "numTasks": 1,
                    "rowCount": 4,
                    "stageIds": [
                      1
                    ],
                    "status": "SUCCEEDED",
                    "submissionTime": "2025-11-18T13:58:29.632GMT",
                    "usageDescription": ""
                  },
                  {
                    "completionTime": "2025-11-18T13:58:27.713GMT",
                    "dataRead": 0,
                    "dataWritten": 0,
                    "description": "Job group for statement 16:\n#Execute through Serveress Spark Compute\n\n# Install required packages:\n# %pip install azure-ai-ml azure-identity pyspark delta-spark\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import ClientSecretCredential\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, MapType\nfrom delta import configure_spark_with_delta_pip\n\n# ---------------------------\n# 2. Service Principal Credentials\n# ---------------------------\ntenant_id = \"c560c3d4-de3a-4441-b221-48582ef51cc4\"\nclient_id = \"cc69fe2b-46cd-4a05-89fa-d83f8fc037d6\"\nclient_secret = \"mny8Q~YARqDd7_m~Hujd6xXPNvi-aiplYxuAqdt0\"\n\ncredential = ClientSecretCredential(tenant_id, client_id, client_secret)\n\n# ---------------------------\n# 3. AML Workspace Details\n# ---------------------------\nSUBSCRIPTION = \"<subscription-id>\"\nRESOURCE_GROUP = \"rg-we-atpws-aml\"\nWS_NAME = \"aml-ws-atp001\"\n\nml_client = MLClient(\n    credential=credential,\n    subscription_id=SUBSCRIPTION,\n    resource_group_name=RESO...",
                    "displayName": "Job group for statement 16:\n#Execute through Serveress Spark Compute\n\n# Install required packages:\n# %pip install azure-ai-ml azure-identity pyspark delta-spark\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import ClientSecretCredential\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, MapType\nfrom delta import configure_spark_with_delta_pip\n\n# ---------------------------\n# 2. Service Principal Credentials\n# ---------------------------\ntenant_id = \"c560c3d4-de3a-4441-b221-48582ef51cc4\"\nclient_id = \"cc69fe2b-46cd-4a05-89fa-d83f8fc037d6\"\nclient_secret = \"mny8Q~YARqDd7_m~Hujd6xXPNvi-aiplYxuAqdt0\"\n\ncredential = ClientSecretCredential(tenant_id, client_id, client_secret)\n\n# ---------------------------\n# 3. AML Workspace Details\n# ---------------------------\nSUBSCRIPTION = \"<subscription-id>\"\nRESOURCE_GROUP = \"rg-we-atpws-aml\"\nWS_NAME = \"aml-ws-atp001\"\n\nml_client = MLClient(\n    credential=credential,\n    subscription_id=SUBSCRIPTION,\n    resource_group_name=RESO...",
                    "jobGroup": "16",
                    "jobId": 1,
                    "jobTags": [],
                    "killedTasksSummary": {},
                    "name": "",
                    "numActiveStages": 0,
                    "numActiveTasks": 0,
                    "numCompletedIndices": 0,
                    "numCompletedStages": 0,
                    "numCompletedTasks": 0,
                    "numFailedStages": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numSkippedStages": 0,
                    "numSkippedTasks": 0,
                    "numTasks": 0,
                    "rowCount": 0,
                    "stageIds": [],
                    "status": "SUCCEEDED",
                    "submissionTime": "2025-11-18T13:58:27.713GMT",
                    "usageDescription": ""
                  },
                  {
                    "completionTime": "2025-11-18T13:58:24.981GMT",
                    "dataRead": 0,
                    "dataWritten": 5706,
                    "description": "Job group for statement 16:\n#Execute through Serveress Spark Compute\n\n# Install required packages:\n# %pip install azure-ai-ml azure-identity pyspark delta-spark\n\nfrom azure.ai.ml import MLClient\nfrom azure.identity import ClientSecretCredential\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, MapType\nfrom delta import configure_spark_with_delta_pip\n\n# ---------------------------\n# 2. Service Principal Credentials\n# ---------------------------\ntenant_id = \"c560c3d4-de3a-4441-b221-48582ef51cc4\"\nclient_id = \"cc69fe2b-46cd-4a05-89fa-d83f8fc037d6\"\nclient_secret = \"mny8Q~YARqDd7_m~Hujd6xXPNvi-aiplYxuAqdt0\"\n\ncredential = ClientSecretCredential(tenant_id, client_id, client_secret)\n\n# ---------------------------\n# 3. AML Workspace Details\n# ---------------------------\nSUBSCRIPTION = \"<subscription-id>\"\nRESOURCE_GROUP = \"rg-we-atpws-aml\"\nWS_NAME = \"aml-ws-atp001\"\n\nml_client = MLClient(\n    credential=credential,\n    subscription_id=SUBSCRIPTION,\n    resource_group_name=RESO...",
                    "displayName": "save at NativeMethodAccessorImpl.java:0",
                    "jobGroup": "16",
                    "jobId": 0,
                    "jobTags": [],
                    "killedTasksSummary": {},
                    "name": "save at NativeMethodAccessorImpl.java:0",
                    "numActiveStages": 0,
                    "numActiveTasks": 0,
                    "numCompletedIndices": 8,
                    "numCompletedStages": 1,
                    "numCompletedTasks": 8,
                    "numFailedStages": 0,
                    "numFailedTasks": 0,
                    "numKilledTasks": 0,
                    "numSkippedStages": 0,
                    "numSkippedTasks": 0,
                    "numTasks": 8,
                    "rowCount": 1,
                    "stageIds": [
                      0
                    ],
                    "status": "SUCCEEDED",
                    "submissionTime": "2025-11-18T13:57:48.214GMT",
                    "usageDescription": ""
                  }
                ],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 3,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "b1e6cefc-f7d3-40b2-90a7-9bef21816697",
              "state": "finished",
              "statement_id": 16,
              "statement_ids": [
                16
              ]
            },
            "text/plain": [
              "StatementMeta(b1e6cefc-f7d3-40b2-90a7-9bef21816697, 6, 16, Finished, Available, Finished)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model card saved as Delta table at: abfss://UnifiedData@onelake.dfs.fabric.microsoft.com/maag_bronze.Lakehouse/Tables/dbo/model_card_delta\n"
          ]
        }
      ],
      "source": [
        "#Execute through Serveress Spark Compute\n",
        "\n",
        "# Install required packages:\n",
        "# %pip install azure-ai-ml azure-identity pyspark delta-spark\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import ClientSecretCredential\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, MapType\n",
        "from delta import configure_spark_with_delta_pip\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Service Principal Credentials\n",
        "# ---------------------------\n",
        "tenant_id = \"<tenant-id>\"\n",
        "client_id = \"<client-id>\"\n",
        "client_secret = \"<client-secret>\"\n",
        "\n",
        "credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
        "\n",
        "# ---------------------------\n",
        "# 3. AML Workspace Details\n",
        "# ---------------------------\n",
        "SUBSCRIPTION = \"<subscription-id>\"\n",
        "RESOURCE_GROUP = \"rg-we-atpws-aml\"\n",
        "WS_NAME = \"aml-ws-atp001\"\n",
        "\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=SUBSCRIPTION,\n",
        "    resource_group_name=RESOURCE_GROUP,\n",
        "    workspace_name=WS_NAME,\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Get Registered Model\n",
        "# ---------------------------\n",
        "model = ml_client.models.get(name=\"credit_default_prediction_standard\", version=\"1\")\n",
        "\n",
        "# ---------------------------\n",
        "# 5. Prepare Model Card Metadata\n",
        "# ---------------------------\n",
        "model_card = {\n",
        "    \"model_name\": model.name,\n",
        "    \"version\": model.version,\n",
        "    \"description\": model.description,\n",
        "    \"tags\": model.tags,\n",
        "    \"properties\": model.properties,\n",
        "    \"validation_status\": model.tags.get(\"validation_status\", \"unknown\"),\n",
        "    \"cost_info\": model.tags.get(\"cost\", \"not provided\")\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# 6. Define Explicit Schema\n",
        "# ---------------------------\n",
        "schema = StructType([\n",
        "    StructField(\"model_name\", StringType(), True),\n",
        "    StructField(\"version\", StringType(), True),\n",
        "    StructField(\"description\", StringType(), True),\n",
        "    StructField(\"tags\", MapType(StringType(), StringType()), True),\n",
        "    StructField(\"properties\", MapType(StringType(), StringType()), True),\n",
        "    StructField(\"validation_status\", StringType(), True),\n",
        "    StructField(\"cost_info\", StringType(), True)\n",
        "])\n",
        "\n",
        "# ---------------------------\n",
        "# 7. Create Spark DataFrame with Schema\n",
        "# ---------------------------\n",
        "model_card_df = spark.createDataFrame([model_card], schema=schema)\n",
        "\n",
        "# ---------------------------\n",
        "# 8. Save as Delta Table in OneLake\n",
        "# ---------------------------\n",
        "delta_path = \"abfss://UnifiedData@onelake.dfs.fabric.microsoft.com/maag_bronze.Lakehouse/Tables/dbo/azureml_card_cardit_model_card\"\n",
        "\n",
        "model_card_df.write.format(\"delta\").mode(\"overwrite\").save(delta_path)\n",
        "\n",
        "print(f\"✅ Model card saved as Delta table at: {delta_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
