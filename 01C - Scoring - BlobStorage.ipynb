{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Predictions in Blob Storage\n",
        "Note: Run this notebook in Azure Machine Learning Compute Instance"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save json payload+prediction from endpoint as table in blob storage\n",
        "simulates POST requesets to Online Endpoit for prediction - save to blob storage\n",
        "\n",
        "**Note:** This examples use the blob storage accesskey to authenticate (not preferred) - see a better approach below. This examples is provided as an alternative example "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# AML configs\n",
        "online_endpoint_name = \"credit-endpoint-78a2c255\"  #Hard-coded enpoint\n",
        "deploy_dir = \"./deploy\"\n",
        "request_file = f\"{deploy_dir}/sample-request.json\"  #Hard-coded Json Payload from previous cell\n",
        "\n",
        "# Blob configs used for storing the prediction\n",
        "BLOB_CONNECTION_STRING = \"DefaultEndpointsProtocol=https;AccountName=<BLOB STORAGE ACCOUNT NAME>;AccountKey=<ACCOUNT KEY>;EndpointSuffix=core.windows.net\"\n",
        "CONTAINER_NAME = \"azureml-batchpredictions\"  #Blob Container\n",
        "csv_file = \"prediction_results.csv\"  #Prediction to be saved as this file\n",
        "\n",
        "# Step 1: Invoke AML endpoint and capture result\n",
        "result = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=request_file,\n",
        "    deployment_name=\"blue\",\n",
        ")\n",
        "\n",
        "# Parse result (assuming JSON or list format)\n",
        "try:\n",
        "    prediction_result = json.loads(result)\n",
        "except json.JSONDecodeError:\n",
        "    # If result is a plain list string like '[1, 0]'\n",
        "    prediction_result = eval(result)\n",
        "\n",
        "print(\"Prediction Result:\", prediction_result)\n",
        "\n",
        "# Step 2: Load input data from request file\n",
        "with open(request_file, \"r\") as f:\n",
        "    request_data = json.load(f)\n",
        "\n",
        "input_data = request_data[\"input_data\"][\"data\"]\n",
        "columns = request_data[\"input_data\"][\"columns\"]\n",
        "\n",
        "# Step 3: Combine input + prediction into DataFrame\n",
        "df = pd.DataFrame(input_data, columns=[f\"col_{c}\" for c in columns])\n",
        "df[\"prediction\"] = prediction_result\n",
        "\n",
        "# Step 4: Save as CSV locally\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "# Step 5: Upload CSV to Azure Blob Storage\n",
        "blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)\n",
        "blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=csv_file)\n",
        "\n",
        "with open(csv_file, \"rb\") as data:\n",
        "    blob_client.upload_blob(data, overwrite=True)\n",
        "\n",
        "print(f\"‚úÖ File uploaded to Blob Storage: {CONTAINER_NAME}/{csv_file}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Prediction Result: [1, 0]\n‚úÖ File uploaded to Blob Storage: azureml-batchpredictions/prediction_results.csv\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1763166979443
        },
        "editable": true,
        "run_control": {
          "frozen": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save batch score prediction as table\n",
        "predict on .csv file - save to blob storage\n",
        "\n",
        "**Note:** This examples doesn't use the blob storage accesskey to authenticate, but instead get the auth details from the datastore (preferred)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.storage.blob import BlobServiceClient\n",
        "import datetime\n",
        "import io\n",
        "\n",
        "# Initialize ML Client\n",
        "credential = DefaultAzureCredential()\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"<subscription-id>\",\n",
        "    resource_group_name=\"rg-we-atpws-aml\",\n",
        "    workspace_name=\"aml-ws-atp001\",\n",
        ")\n",
        "\n",
        "# Endpoint configuration\n",
        "online_endpoint_name = \"credit-endpoint-78a2c255\"\n",
        "\n",
        "# Step 1: Load your CSV file from datastore\n",
        "input_uri = \"azureml://subscriptions/<subscription-id>/resourcegroups/rg-we-atpws-aml/workspaces/aml-ws-atp001/datastores/onelake_example_id/paths/raw-files/for-batch-scoring/data_with_headers.csv\"\n",
        "df = pd.read_csv(input_uri)\n",
        "\n",
        "# Step 2: Convert DataFrame to the endpoint's expected JSON format\n",
        "request_data = {\n",
        "    \"input_data\": {\n",
        "        \"columns\": list(range(len(df.columns))),\n",
        "        \"index\": list(range(len(df))),\n",
        "        \"data\": df.values.tolist()\n",
        "    }\n",
        "}\n",
        "\n",
        "# Step 3: Save as temporary JSON file\n",
        "temp_request_file = \"./batch_request.json\"\n",
        "with open(temp_request_file, \"w\") as f:\n",
        "    json.dump(request_data, f)\n",
        "\n",
        "# Step 4: Invoke endpoint for batch scoring\n",
        "result = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=online_endpoint_name,\n",
        "    request_file=temp_request_file,\n",
        "    deployment_name=\"blue\",\n",
        ")\n",
        "\n",
        "# Step 5: Parse predictions\n",
        "try:\n",
        "    predictions = json.loads(result)\n",
        "except json.JSONDecodeError:\n",
        "    predictions = eval(result)\n",
        "\n",
        "# Step 6: Add predictions to original DataFrame\n",
        "df['prediction'] = predictions\n",
        "\n",
        "# Step 7: Save results to workspaceblobstore using Azure Blob Storage SDK\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "datastore_name = \"workspaceblobstore\"\n",
        "# output_path = f\"batch-scoring-results/scored_results_{timestamp}.csv\"\n",
        "output_path = f\"prediction_results.csv\"\n",
        "\n",
        "# Get the datastore details\n",
        "datastore = ml_client.datastores.get(datastore_name)\n",
        "\n",
        "# Create blob service client using credential\n",
        "blob_service_client = BlobServiceClient(\n",
        "    account_url=f\"https://{datastore.account_name}.blob.core.windows.net\",\n",
        "    credential=credential\n",
        ")\n",
        "\n",
        "# Get blob client\n",
        "blob_client = blob_service_client.get_blob_client(\n",
        "    container=\"azureml-batchpredictions\", #datastore.container_name,\n",
        "    blob=output_path\n",
        ")\n",
        "\n",
        "# Convert DataFrame to CSV in memory\n",
        "csv_buffer = io.StringIO()\n",
        "df.to_csv(csv_buffer, index=False)\n",
        "csv_data = csv_buffer.getvalue()\n",
        "\n",
        "# Upload to blob storage\n",
        "blob_client.upload_blob(csv_data, overwrite=True)\n",
        "\n",
        "# Build the full URI for reference\n",
        "output_uri = f\"azureml://subscriptions/{ml_client.subscription_id}/resourcegroups/{ml_client.resource_group_name}/workspaces/{ml_client.workspace_name}/datastores/{datastore_name}/paths/{output_path}\"\n",
        "\n",
        "print(f\"‚úÖ Batch scoring complete!\")\n",
        "print(f\"Total records scored: {len(df)}\")\n",
        "print(f\"üìÅ Results saved to datastore: {datastore_name}\")\n",
        "print(f\"üìÇ Path: {output_path}\")\n",
        "print(f\"\\nFull URI: {output_uri}\")\n",
        "print(f\"\\nSample predictions:\\n{df[['prediction']].head()}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "‚úÖ Batch scoring complete!\nTotal records scored: 10\nüìÅ Results saved to datastore: workspaceblobstore\nüìÇ Path: prediction_results.csv\n\nFull URI: azureml://subscriptions/<subscription-id>/resourcegroups/rg-we-atpws-aml/workspaces/aml-ws-atp001/datastores/workspaceblobstore/paths/prediction_results.csv\n\nSample predictions:\n   prediction\n0           1\n1           0\n2           0\n3           1\n4           0\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1763198482527
        },
        "editable": false,
        "run_control": {
          "frozen": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ExPERIEMENTS"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install azure-ai-ml azure-identity pyspark delta-spark"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean up resources"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "editable": false,
        "run_control": {
          "frozen": true
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}